NAME: 'pretraining_all'

MODEL:
    model_type: 'SWINUNETR'  # 'mala' or 'superhuman' or 'UNETR' or 'Resnet50'
    input_nc: 1
    output_nc: 1
    return_dict: False
    unetr_size: [32,160,160]
    patch_size: [4,16,16]
    kernel_size: [1,3,3]
    if_sigmoid: True
    # for 'mala':
    init_mode_mala: 'kaiming'
    # for 'superhuman':
    filters: 
        - 28
        - 36
        - 48
        - 64
        - 80
    upsample_mode: 'transposeS'  # 'bilinear', 'nearest', 'transpose', 'transposeS'
    decode_ratio: 1
    merge_mode: 'cat'  # 'add', 'cat'
    pad_mode: 'zero'  # 'zero', 'replicate'
    bn_mode: 'async'  # 'sync', 'async'
    relu_mode: 'elu'  # 'elu', 'relu', 'leaky'
    init_mode: 'kaiming_normal'  # 'kaiming_normal', 'kaiming_uniform', 'xavier_normal', 'xavier_uniform'

TRAIN:
    resume: False
    if_valid: True
    cache_path: '/data/ydchen/VLP/NIPS0429/RESULT/miccai23_cashes'
    save_path: '/data/ydchen/VLP/NIPS0429/MODEL/miccai23_models' 
    record_path: '/data/ydchen/VLP/NIPS0429/LOGs/miccai23_models'
    pad: 0
    loss_func: 'MSE'   # 'MSE', 'L1'
    random_choice: False
    multi_scale_mse: False
    free_layers: 9
    opt_type: 'adam'
    power: 1.5
    if_cuda: True

    random_seed: 555  # -1 is none

trainer:
  batch_size: 2
  test_batch_size: 200
  checkpoint_interval: 100000
  save_iters: 20000
  max_epochs: 200
  max_iterations: 1000000
  crop_size: [32,320,320]
  net_padding: [0,0,0]
  contranstive: False
  backbone: 'Vit3d' # 'SWINUNETR' or 'resnet50' or 'Vit3d'
  lr: 2.0e-4
  num_workers: 0
  test_interval: 2
  visual_dir: '/data/ydchen/VLP/MODEL/bigModel_MAE_0527/visual'
  visual_iters: 100
  loss: 'only_clip' # 
  smooth: 'exp' # you don't need smooth here, because no prior knowledege yet
  ratio: 0.2
  log_dir: '/data/ydchen/VLP/MODEL/bigModel_MAE_0527/LOGs'
  log_name_BYOL: 'BYOL_all_230426.log'
  log_name_simsiam: 'SimSiam_all_230426.log'
  log_name_MAE: 'MAE_huge.log'
  simsiam_dir: '/data/ydchen/VLP/NIPS0429/MODEL/Neurips23_imgSSL/Siasiam0426'
  BYOL_dir: '/data/ydchen/VLP/NIPS0429/MODEL/Neurips23_imgSSL/BYOL0426'
  MAE_dir: '/h3cstore_ns/LVM/MAE_huge'

DATA:
    dataset_name: 'cremi-C'  # 'snemi3d-ac3', 'cremi-C'
    unlabel_dataset: 'cremi-C-200'  # 'ac3_ac4', 'ac4_around', 'cremi-C-200', 'cremi-all'
    type: 'all' # 'CT', 'MRI', 'EM','all'
    unlabel_datalist: 
        - 'AC4_5.h5'
        - 'AC4_6.h5'
        - 'AC4_7.h5'
        - 'AC4_9.h5'
        - 'AC4_10.h5'
        - 'AC4_11.h5'
        - 'AC4_12.h5'
        - 'AC4_13.h5'
    folder_name: '/data/ydchen/VLP/NIPS0429/DATASET/miccai_pretrain_data'
    test_split: 25  # for speed
    unlabel_split: 100
    unlabel_split_rate: 1
    data_folder: './data'
    if_norm_images: False
    if_scale_aug_labeled: True
    scale_factor: 1.5
    if_filp_aug_labeled: False
    if_rotation_aug_labeled: False
    if_intensity_aug_labeled: False
    if_elastic_aug_labeled: False
    if_noise_aug_labeled: False
    min_noise_std: 0.01
    max_noise_std: 0.2
    if_mask_aug_labeled: False
    if_blur_aug_labeled: True
    min_kernel_size: 3
    max_kernel_size: 9
    min_sigma: 0
    max_sigma: 2

    per_mode: 1
    if_scale_aug_unlabel: False
    if_filp_aug_unlabel: True
    if_rotation_aug_unlabel: True
    if_intensity_aug_unlabel: True
    if_noise_aug_unlabel: True
    if_blur_aug_unlabel: True
    if_mask_aug_unlabel: True
    if_sobel_aug_unlabel: False
    if_mixup_aug_unlabel: False
    if_misalign_aug_unlabel: False
    if_elastic_aug_unlabel: False
    if_artifact_aug_unlabel: False
    if_missing_aug_unlabel: False
    if_blurenhanced_aug_unlabel: True

TEST:
    pad: 0
    model_name: ' '

network:
  img_model: resnet50
  ### this part does not control builder/trainer
  text_model: bert
  free_layers: 6
  text_model_arch: general # specialized/general
  feature_dim: 768

  projection_head:
    mlp_hidden_size: 2048
    projection_size: 768
  ###

### device setting control by torchrun, not this part
device_id: 0
device_num: 1
###

optimizer:
  params:
    lr: 2.0e-5
    # momentum: 0.9
    weight_decay: 5.0e-2

wandb_name: 'generate_then_optimize_pretrain'